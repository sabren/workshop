#!/usr/bin/env python2.5
from narrative import testcase, addMethod
from strongbox import *
from unittest import TestCase
from clerks import *
from storage import RamStorage
import unittest

# * intro: what are clerks?
"""
Clerks are little objects that fetch and store strongbox-style
data objects from a database or other data store. If your data
store is a relational database, then you can think of a Clerk as
an object-relational-mapper.

Clerks also work with strongboxen to let you load data on the fly.
That is, if you have a tree of objects, you can load the top one,
and the children are only loaded when you actually access them.

Note that the objects never talk to the database directly. Why? Well,
the main idea is that sometimes, especially for testing, you want
to create objects that don't live in the database. I used to use
records that were tightly bound to the database, but I found it
was easier to just use one 'Clerk' object.

"""

# * test conventions used for Clerk

class Record(Strongbox):
    ID = attr(long)
    value = attr(str)
    next = link(lambda : Record)

class Node(Strongbox):
    ID = attr(long)
    data = attr(str)
    parent = link(lambda : Node)
    kids = linkset((lambda : Node), "parent")

RECORD_TABLE = "record_table"
NODE_TABLE = "node_table"

TEST_SCHEMA = Schema({
    Node: NODE_TABLE,
    Node.parent: "parentID",
    Record: RECORD_TABLE,
    Record.next: "nextID",
})


class ClerkTest(unittest.TestCase):
    def setUp(self):
        self.storage = RamStorage()
        self.clerk = Clerk(self.storage, TEST_SCHEMA)



# * basic interface: .store and .fetch
"""
You need these things to use clerk:

  - a strongbox data class (see strongbox.py)
  - an attribute called ID on the strongbox
  - a storage object (see storage.py)
  - a clerks.Schema object (see below)

We'll store each Record in a table called 'records_table'
and we'll use a column called 'nextID' to hold the ID
of the 'next' link.

To make this work, we need to define a schema.
The schema is just a wrapper around a dictionary,
which maps classes to table names and link attributes
to foreign key column names.

Here is the schema for our Record object:
"""


"""
We'll just use a RamStorage instance for our storage
so we don't have to worry about setting up a database.

Here's how to store and retrieve a record:
"""

@addMethod(ClerkTest)
def test_basics(self):

    # create and store a record
    r = Record(value='hello')

    # notice the ID is blank:
    assert r.ID == 0 
    assert r.next is None

    # now store it:
    self.clerk.store(r)

    # note that the object is updated in place:
    assert r.ID == 1
    assert r.next is None

    # here's what's in the table:
    # note the nextID is 0 because r.next is None
    db_row = self.storage.match(RECORD_TABLE)
    assert db_row == [{"ID":1, "value":"hello", "nextID":0}], db_row

    # now we can retrieve it by passing the ID to fetch
    a = self.clerk.fetch(Record, 1)

    # we can also pass in a where clause if we KNOW we'll only
    # get one record back. (To match more than one record, use
    # match. - see below.)
    b = self.clerk.fetch(Record, value='hello')

    # and note that we always get the same object,
    # so if you change one, they all change.
    c = self.clerk.fetch(Record, 1)
    assert a is r
    assert b is r
    assert c is r


# * storing objects

@addMethod(ClerkTest)
def test_store(self):
    self.clerk.store(Record())
    actual = self.storage.match(RECORD_TABLE)
    assert actual == [{"ID":1, "value":"", "nextID":0}], actual
    r = self.clerk.fetch(Record, 1)
    assert r.next is None


@addMethod(ClerkTest)
def test_store_again(self):
    self.clerk.store(Record())
    r = self.clerk.fetch(Record, 1)
    r.value = "abc"
    self.clerk.store(r)

@addMethod(ClerkTest)
def test_store_link(self):
    r = Record(value="a")
    r.next = Record(value="b")

    self.clerk.store(r)
    del r
    r = self.clerk.match(Record, value="a")[0]
    assert r.ID == 2, "didn't save links first!"
    assert r.next is not None, "didn't store the link"
    assert r.next.value=="b", "didn't store link correctly"

    r.next = None
    self.clerk.store(r)
    r = self.clerk.match(Record, value="a")[0]
    assert r.next is None, "didn't delete link!"

    r = Record(value="noNext")
    self.clerk.store(r)
    r = self.clerk.fetch(Record, value="noNext")
    assert r.next is None

@addMethod(ClerkTest)
def test_store_linksets(self):
    n1 = Node(data="a")
    n1.kids << Node(data="aa")
    n1.kids << Node(data="ab")
    n1.kids[1].kids << Node(data="aba")
    self.clerk.store(n1)
    assert len(n1.kids)== 2, [(k.ID, k.data) for k in n1.kids]        

    n = self.clerk.fetch(Node, 1)
    assert n is n1
    assert len(n1.kids)== 2, \
           "fetch corrupted kids: %s" % [(k.ID, k.data) for k in n1.kids]

    assert n.ID == 1, "didn't save parent of linkset first!"
    assert len(n.kids)== 2, \
           "didn't store the linkset: %s" % [(k.ID, k.data) for k in n.kids]
    assert n.kids[0].data=="aa", "didn't store link correctly"
    assert n.kids[1].data=="ab", "didn't store link correctly"
    assert n.kids[1].kids[0].data=="aba", "didn't store link correctly"
    assert n.kids[0].parent is n
    assert n.kids[1].parent is n

    n.kids[1].parent=None
    n.kids.remove(n.kids[1])
    self.clerk.store(n)
    n = self.clerk.match(Node, data="a")[0]
    assert len(n.kids) == 1


# * fetching objects

@addMethod(ClerkTest)
def test_fetch(self):
    self.clerk.store(Record(value="howdy"))

    # we can pass in an ID:
    obj = self.clerk.fetch(Record, 1)
    assert obj.value == "howdy"

    # or we can use keywords:
    obj = self.clerk.fetch(Record, value="howdy")
    assert obj.value == "howdy"


def test_fetch_from_wide_table(self):
    """
    Supose a strongbox has 1 slot, but the table has 2+ columns.
    We can't just jam those columns into the strongbox,
    because strongbox is *designed* to blow up if you try
    to add new attributes.

    But on the other hand, a DBA should be able to add columns
    to the databaes without breaking the code and causing
    AttributeErrors all over the place.

    Instead, Clerk should only use the columns that have
    matching attributes, and simply ignore the others.

    This sorta violates the concept of OnceAndOnlyOnce,
    because now the tables can be out of sync with the
    data model, but I think it's better than the alternative,
    and this is the sort of thing one could check with
    an automated tool.

    #@TODO: write tool to compare DB and object models :)
    """
    try:
        self.storage.store(RECORD_TABLE, value="a", extra_column="EEK!")
        a = self.clerk.fetch(Record, 1)
        a.value="aa"
        self.clerk.store(a)
    except AttributeError:
        self.fail("shouldn't die when columns outnumber attributes")


@addMethod(ClerkTest)
def test_fetch_with_calculated_columns(self):
    """
    Along those lines, if the table caches calculated
    fields we need to filter them out when we fetch
    """
    class Calculated(StrongBox):
        ID = attr(int)
        a = attr(int)
        def get_b(self):
            return 5
        c = attr(int)
    calc = self.clerk._rowToInstance({"ID":0, "a":1,"b":2,"c":3}, Calculated)
    assert calc.a == 1
    assert calc.b == 5
    assert calc.c == 3

    # the point is, b has to be ignored because
    # normally it raises an error:
    self.assertRaises(AttributeError, setattr, calc, "b", 2)



# * matching multiple objects

@addMethod(ClerkTest)
def test_match(self):
    self.clerk.store(Record(value="one"))
    self.clerk.store(Record(value="two"))
    self.clerk.store(Record(value="two"))
    assert len(self.clerk.match(Record, value="zero")) == 0
    assert len(self.clerk.match(Record, value="one")) == 1
    assert len(self.clerk.match(Record, value="two")) == 2


@addMethod(ClerkTest)
def test_matchOne(self):
    self.clerk.store(Record(value="one"))
    self.clerk.store(Record(value="two"))
    self.clerk.store(Record(value="two"))

    try:
        self.clerk.matchOne(Record, value="zero")
        self.fail("should have failed for not matching")
    except LookupError: pass

    assert isinstance(self.clerk.matchOne(Record, value="one"),
                      Record)

    try:
        self.clerk.matchOne(Record, value="two")
        self.fail("should have failed for matching two")
    except LookupError: pass



# * deleting objects


@addMethod(ClerkTest)
def test_delete(self):
    self.test_fetch()
    self.clerk.delete(Record, 1)
    assert self.storage.match(RECORD_TABLE) == []



# * Lazyloading with Injectors
# ** what are injectors?
"""
Imagine that you have a tree of objects 10 levels deep. For
example, a relationship mapping bosses to subordinates.
You don't want to have to load the whole tree just to retrieve
the CEO of a company.

If we'd gone the SQLObject route, then every object knows
about the database, so it's easy to for the object to just load
each level of the hierarchy directly. But our objects don't
know anything about how they're stored. So how to handle that?

What we do is we do is create a shell object. That is, an
object that holds the place of a record but not the data.

Imagine a tree that looks like this:

        office - manager - projects
                   |
        office - workers - projects


class Office:
    manager = link(lambda: Person)
    workers = linkset(lambda: Person)

class Person:
    office = link(Office)
    projects = linkset(lambda: Project)

class Project

# todo: this ought to be modelled with roles, so find
# a better example for this kind of thing.

That is, everyone in each office is assigned to
certain projects, and every office has some number
of workers and one manager. This is sort of a contrived
example, but it allows us to look at two situations:
the list of manager projects for an office and the
list of worker projects for an office.

If you imagine a database with this information, you can see
it's easy to get all the offices: select * from office.
In our scheme here, it looks like clerk.match(Office)

In the database, the Office table would have managerID
column, and there would be a separate table for
workers: ID, officeID, personID

...

I'm trying to show that we have empty objects, and you can't
tell what state they're in until they're observed.

PEAK seems to do this with bindings...
SQLObject seems to just hold on to the database connection.
clerk takes advantage of injectors.

Start with linkset. They're just like select all.

But what if it's a 1-1 relationship? some options:

  a load each one individually (explosion!)
  b do the join up front in sql
  c load and cache the whole table
  d don't load anything

Arlo takes option c or d. option b would be nice but isn't
implemented.  So I want to show that you can load a hollow manager
object and it will know it's ID, and can therefore load its projects
without ever reading the manager data from the database!!

What about the tree explosion? Well, you can just read the
whole table at once up front...



302 stopped to fold laundry ----- [0116.2006 03:02PM]

"""
# ** LinkInjector



@testcase
def test_link_inject(self):

    class Foreign(Strongbox):
        ID = attr(long)
        data = attr(str)

        # there's no explicit test for this,
        # but this is here to make sure that inject
        # handles stored calculated fields properly
        def get_calc(self):
            return 2+2

    class Local(Strongbox):
        ref = link(Foreign)



    schema = Schema({
        Foreign: "foregin",
        Local: "local",
        Local.ref: "foreignID",
    })
    clerk = RamClerk(schema)

    obj = Local()
    assert obj.ref is None

    clerk.store(Foreign(data="Here I come to save the day!"))

    obj.ref = Foreign(ID=1)
    obj.ref.addInjector(LinkInjector(clerk, Foreign, 1).inject)
    assert len(obj.ref.private.injectors) == 1

    # should be able to fetch the ID without triggering load
    assert obj.ref.ID == 1
    assert obj.ref.private.data == ""
    assert len(obj.ref.private.injectors) == 1

    # but getting any other field triggers the load!
    assert obj.ref.data == "Here I come to save the day!"
    assert len(obj.ref.private.injectors) == 0


@testcase
def test_linkinjector_with_linkset(self):
    """
    what happens if the thing we're injecting
    has a linkset of its own (this used to fail)
    """

    class Kid(Strongbox):
        ID = attr(long)
        parent = link(lambda : Parent)

    class Parent(Strongbox):
        ID = attr(long)
        name = attr(str)
        kids = linkset(Kid, "parent")

    class Uncle(Strongbox):
        brother = link(Parent)

    schema = Schema({
        Kid: "kid",
        Kid.parent: "parentID",
        Parent: "parent",
        Uncle: "uncle",
        Uncle.brother: "brotherID",
    })
    clerk = RamClerk(schema)


    kid = Kid()
    dad = Parent(name="Brother Dad")
    dad.kids << kid
    clerk.store(dad)

    unc = Uncle()
    unc.brother = Parent(ID=1)
    unc.brother.addInjector(LinkInjector(clerk, Parent, 1).inject)

    ## this next line threw an AttributeError because the
    ## injector tried to include "kids" in the .update() call
    assert unc.brother.name=="Brother Dad"


@testcase
def test_linkset_inject(self):


    class Content(Strongbox):
        ID = attr(long)
        box = link(lambda : Package)
        data = attr(str)


    class Package(Strongbox):
        ID = attr(long)
        refs = linkset(Content, "box")




    ms = RamStorage()
    ms.store("Package")
    ms.store("Content", data="I'm content", boxID=1)
    ms.store("Content", data="I'm mal content", boxID=1)

    schema = Schema({
        Content: "content",
        Content.box: "boxID",
        Package: "package",
    })

    clerk = Clerk(ms, schema)

    pak = Package()
    pak.refs << Content(data="I'm content", box=pak)
    pak.refs << Content(data="I'm malcontent", box=pak)
    pak = clerk.store(pak)

    # @TODO: should be able to add to the index without
    # triggering load (for performance reasons)
    # -- so long as any other use DOES trigger load --


    clerk.cache.clear()
    pak = clerk.fetch(Package, ID=1)

    # asking for .refs will trigger the load:
    assert len(pak.private.refs) == 0, pak.private.refs
    assert len(pak.refs) == 2

    # make sure it works with << on a fresh load too:
    newClerk = Clerk(clerk.storage, clerk.schema)
    pak = newClerk.fetch(Package, ID=1)
    assert len(pak.private.refs) == 0
    pak.refs << Content(data="I'm malcontent",  box=pak)
    assert len(pak.refs) == 3


@addMethod(ClerkTest)
def test_link_injection(self):
    self.storage.store(RECORD_TABLE, value="a", nextID=2)
    self.storage.store(RECORD_TABLE, value="b", nextID=3)
    self.storage.store(RECORD_TABLE, value="c", nextID=None)

    a = self.clerk.fetch(Record, 1)

    assert a.value == "a"
    assert a.next.value == "b"
    assert a.next.next.value == "c"
    assert a.next.next.next is None


@addMethod(ClerkTest)
def test_linkset_injection(self):
    self.storage.store(NODE_TABLE, data="top", parentID=None)
    self.storage.store(NODE_TABLE, data="a",   parentID=1)
    self.storage.store(NODE_TABLE, data="a.a", parentID=2)
    self.storage.store(NODE_TABLE, data="b",   parentID=1)

    top = self.clerk.fetch(Node, 1)
    assert top.kids[0].data == "a"
    assert top.kids[1].data == "b"
    assert top.kids[1].kids == []
    assert top.kids[0].kids[0].data == "a.a"





# * dirty little objects

@addMethod(ClerkTest)
def test_dirt(self):
    # dirty by default (already tested in strongbox)
    r = Record()
    assert r.private.isDirty

    # but not after a store:
    r = self.clerk.store(r)
    assert not r.private.isDirty

    # and not after a fetch:
    r = self.clerk.fetch(Record, ID=1)
    assert not r.private.isDirty

    # or a match:
    r = self.clerk.match(Record)[0]
    assert not r.private.isDirty


@addMethod(ClerkTest)
def test_recursion(self):
    r = Record()
    r.next = Record()
    r.next.next = r
    assert r.private.isDirty
    assert r.next.private.isDirty
    r = self.clerk.store(r)
    assert r.ID == 2
    assert r.next.ID == 1

    r = self.clerk.fetch(Record, 2)
    assert not r.private.isDirty
    assert not r.next.private.isDirty


    ## and the same thing for linksets:
    n = Node()
    n.kids << Node()
    n.kids[0].kids << n
    assert n.private.isDirty
    assert n.kids[0].private.isDirty
    n = self.clerk.store(n)

# * stubs

@addMethod(ClerkTest)
def test_stub(self):
    self.clerk.store(Record(value="a", next=Record(value="b")))
    self.clerk.cache.clear()
    recA = self.clerk.fetch(Record, value="a")
    recB = self.clerk.fetch(Record, value="b")
    assert recA.next.ID == recB.ID
    assert recA.next is recB


# * caching objects
"""
The cache is currently implemented as a dictionary mapping
clases to dictionaries of instances.

The reason for this organization is so that we can cache
entire tables of objects at once, and can quickly scan through
those tables ourselves when we need to load a linkset.

Right now, cache queries are limited to simple equalities.
That is, you can match where a particular field equals a
particular value, but you can't query for fields 'greater than'
the value.

Ideally, *every* match would use these cached tables, but
that won't work unless we implement our own little query
language. (A start on this actually exists in storage with
the QueryBuilder but it doesn't currenly work with clerks.)

"""
# ** cache basics
"""
The basic test of the cache: if you store something and
fetch it back, you get the exact same instance in memory.
"""
@addMethod(ClerkTest)
def test_cached_fetch(self):
    self.clerk.store(Record(value="one"))
    rec1a = self.clerk.fetch(Record, 1)
    rec1b = self.clerk.fetch(Record, 1)
    assert rec1a is rec1b

    n = Record()
    r = Record(next=n)        
    assert self.clerk.store(r) is r
    assert self.clerk.cache[(Record, r.ID)] is r
    assert self.clerk.cache[(Record, n.ID)] is n
    assert self.clerk.cache[(Record, n.ID)] is r.next

@addMethod(ClerkTest)
def test_cached_match(self):
    rb = self.clerk.store(Record(value="b"))
    ra = self.clerk.store(Record(value="a", next=rb))

    a,b = self.clerk.match(Record, orderBy="value")
    assert a is ra
    assert b is rb

# ** caching entire tables

@addMethod(ClerkTest)
def test_cached_class(self):
    """
    This shows that if we run cacheAll(Record)
    then we wind up with 4 records in the cache.
    and the class is noted in the cache's allCached
    dictionary.
    """
    self.storage.store(RECORD_TABLE, value='a')
    self.storage.store(RECORD_TABLE, value='b')
    self.storage.store(RECORD_TABLE, value='c')
    self.storage.store(RECORD_TABLE, value='d')
    self.clerk.cacheAll(Record)
    assert Record in self.clerk.cache.allCached
    assert len(self.clerk.cache.data[Record].keys()) == 4
    
    """
    Now for the kicker:
    We wipe the underlying table...
    """
    for x in range(1,5): self.storage.delete(RECORD_TABLE, x)
    assert self.storage.match(RECORD_TABLE) == []

    """
    But we can still get the object:
    """
    a = self.clerk.matchOne(Record, value='a')
    assert a.ID == 1
    assert a.value == 'a'


# ** speeding up linksets with cached tables
"""
If we know that the entire table is cached, we can speed
up linksets based on that table considerably.

The code that implements this is actually in LinkSetInjector.
"""
@testcase
def test_cached_linksets(test):

    class Parent(Strongbox):
        ID = attr(long)
        value = attr(str)
        kids = linkset((lambda : Child), "parent")

    class Child(Strongbox):
        ID = attr(long)
        value = attr(str)
        parent = link(Parent)

    child_table = 'ct'
    parent_table = 'pt'
    schema = Schema({
        Parent : parent_table,
        Child  : child_table,
        Child.parent : "parentID",
    })

    storage = RamStorage()
    clerk = Clerk(storage, schema)

    # set up our data:
    
    storage.store(parent_table, value='big_daddy')
    
    storage.store(child_table, value='a', parentID=0)
    storage.store(child_table, value='b', parentID=1)
    storage.store(child_table, value='c', parentID=1)
    storage.store(child_table, value='d', parentID=0)


    # Note: we could do this first:
    # big_daddy = clerk.fetch(Parent, 1)
    # *BUT* there used to be a case where
    # doing this first caused the test to pass
    # and doing it later caused the test to fail.
    # so... do it later to expose the bug.


    # cache it:
    clerk.cacheAll(Child)

    assert Parent.kids.back =="parent"
    assert Parent.kids.type == Child
    assert Child in clerk.cache.allCached
    assert Child not in clerk.cache.index

    # delete the underlying data, so there's no confusion
    for x in range(1,5):
        storage.delete(child_table, x)

    # grab the parent:
    big_daddy = clerk.fetch(Parent, 1)

    # note the parent is a stub:
    assert big_daddy.private.value == ''
    assert len(big_daddy.private.kids)==0
   

    # the stub is associated with the cached child objects
    test.assertEquals(4, len(clerk.cache.data[Child].values()))
    child2 = clerk.cache.data[Child][2]
    assert child2.parent is big_daddy


    # the stub should have two injectors:
    # a linkinjector (to fill in its own data)
    # and a linkset injector (for .kids)
    test.assertEquals(2, len(big_daddy.private.injectors))


    # now this should pull the data out of the cache:
    test.assertEquals(2, len(big_daddy.kids))


    # but note that it is *still* a stub!!
    assert big_daddy.private.value == ''


# ** indexing the cache by a column
"""
The above is all well and good, but if the underlying
database has an index on the foreign key, it's probably
got very near an O(1) lookup, and and our lookups are
going to be O(n) because we're looping through n records
every time we build a linkset.

We need to do what the database does, and index the cache.
"""
@addMethod(ClerkTest)
def test_cache_hash(self):

    self.storage.store(NODE_TABLE, data='root', parentID=0)
    self.storage.store(NODE_TABLE, data='1a', parentID=1)
    self.storage.store(NODE_TABLE, data='1b', parentID=1)
    self.storage.store(NODE_TABLE, data='1c', parentID=1)
    self.storage.store(NODE_TABLE, data='2a', parentID=2)
    self.storage.store(NODE_TABLE, data='2b', parentID=2)
    self.storage.store(NODE_TABLE, data='2c', parentID=2)

    self.clerk.cacheAll(Node, index=['data','parent'])

    n1a = self.clerk.cache.index[Node]['data']['1a'][0]
    assert n1a.data == '1a'

    p1 = n1a.parent
    assert p1.ID == 1
    
    #import pdb; pdb.set_trace()
    self.assertEquals(3, len(self.clerk.cache.index[Node]['parent'][p1.ID]))
    
    

# * callbacks

@testcase
def test_callbacks(self):

    class Thing(Strongbox):
        ID = attr(long)
        x = attr(str)

    class OtherThing(Strongbox):
        ID = attr(long)
        x = attr(str)

    queue = []
    schema = Schema({
        Thing: "thing",
        OtherThing: "other",
    })

    clerk = CallbackClerk(RamStorage(), schema)
    clerk.onStore(Thing, queue.append)

    clerk.store(Thing(x="a"))
    clerk.store(Thing(x="b"))
    clerk.store(OtherThing(x="not me"))


    queue2 = []
    clerk.onStore(Thing, queue2.append)
    clerk.store(Thing(x="c"))

    # "c" should wind up in both:
    assert len(queue) == 3
    assert "".join([t.x for t in queue]) == "abc"

    assert len(queue2) == 1
    assert queue2[0].x=="c"



# * schema objects

@testcase
def test_schema(self):

    class Loop(Strongbox):
        next = link(lambda : Loop)
        tree = linkset((lambda : Loop), "next")

    s = Schema({
        Loop: "loop_table",
        Loop.next: "nextID",
    })
    assert s.tableForClass(Loop) == "loop_table"
    assert s.columnForLink(Loop.next) == "nextID"

    # it should be smart enough to infer the
    # links, but note that first have to clear out
    # the lambdas by actually instantiating a Loop
    # @TODO: should schema clear the lambda for us?
    x = Loop()
    assert s.tableForLink(Loop.next) == "loop_table"
    assert s.tableForLinkSet(Loop.tree) == "loop_table"
    assert s.columnForLinkSet(Loop.tree) == "nextID"



# * regression tests

@testcase
def disappearing_events_regression_test(self):
    """
    This bug came from duckbill. A subscription
    would post events to its account, and then
    when it showed the statements the new events
    would be the only ones to show up - even though
    there were still others in the database.

    In other words, the injector wasn't working.

    Turns out the problem was that the sub.account
    stub didn't have injectors on ITS dependent
    objects. That's why I now replace .private
    in LinkInjector.inject()
    """
    class Evt(Strongbox):
        ID = attr(long)
        evt = attr(str)
        acc = link(lambda : Acc)
    class Sub(Strongbox):
        ID = attr(long)
        acc = link(lambda : Acc)
    class Acc(Strongbox):
        ID = attr(long)
        subs = linkset(Sub, "acc")
        evts = linkset(Evt, "acc")
    schema = Schema({
        Evt:"evt",
        Sub:"sub",
        Acc:"acc",
        Evt.acc: "accID",
        Sub.acc: "accID",
    })
    st = RamStorage()
    c1 = Clerk(st, schema)

    # store an account with two events and one sub:
    a = Acc()
    a.evts << Evt(evt="1")
    a.evts << Evt(evt="2")
    assert a.private.isDirty
    a.subs << Sub()
    c1.DEBUG = 1
    c1.store(a)

    # new clerk, new cache:
    c2 = Clerk(st, schema)

    # add more events while s.acc is a stub
    s = c2.fetch(Sub, ID=1)
    assert s.private.isDirty==False
    assert len(s.acc.evts) == 2, [e.evt for e in s.acc.evts]
    s.acc.evts << Evt(evt="3")
    #assert len(s.acc.evts) == 1, [e.evt for e in s.acc.evts]
    assert len(s.acc.evts) == 3, [e.evt for e in s.acc.evts]
    c2.DEBUG = 0
    c2.store(s)
    a2 = c2.fetch(Acc, ID=a.ID)

    assert a is not a2

    # we should now have all three events,
    # but we were getting only the third one:
    assert len(a2.evts) == 3, [e.evt for e in a2.evts]
    

@testcase
def complex_recursion_regression_test(self):
    """
    test case from cornerhost that exposed a bug.
    this is probably redundant given test_recursion
    but it doesn't hurt to keep it around. :)

    This test is complicated. Basically it sets up
    several classes that refer to each other in a loop
    and makes sure it's possible to save them without
    infinite recursion.

    @TODO: isInstance(LinkSetInjector) in Clerk.py need tests
    It ought to do some kind of polymorphism magic anyway.
    (huh??)
    """

    class User(Strongbox):
        ID = attr(long)
        username = attr(str)
        domains = linkset((lambda : Domain),"user")
        sites = linkset((lambda : Site),"user")
    class Domain(Strongbox):
        ID = attr(long)
        user = link(User)
        name = attr(str)
        site = link(lambda : Site)            
    class Site(Strongbox):
        ID = attr(long)
        user = link(User)
        domain = link(Domain)
    dbMap = Schema({
        User:"user",
        Domain:"domain",
        Domain.user: "userID",
        Domain.site: "siteID",
        Site:"site",
        Site.user: "userID",
        Site.domain: "domainID",
    })

    clerk = Clerk(RamStorage(), dbMap)
    u = clerk.store(User(username="ftempy"))
    u = clerk.match(User,username="ftempy")[0]
    d = clerk.store(Domain(name="ftempy.com", user=u))
    assert d.user, "didn't follow link before fetch"
    d = clerk.match(Domain, name="ftempy.com")[0]

    # the bug was here: it only happened if User had .domains
    # I think because it was a linkset, and the linkset had
    # an injector. Fixed by inlining the injector test into
    # Clekr.store:
    assert d.user, "didn't follow link after fetch"
    assert d.user.ID == u.ID

    # ah, but then we had an infinite recursion problem
    # with site, but I fixed that with private.isDirty:
    d.site = clerk.store(Site(domain=d))
    d = clerk.store(d)
    assert d.site.domain.name == "ftempy.com"

    # and again here:
    d = clerk.fetch(Domain, 1)
    assert not d.private.isDirty
    assert not d.site.private.isDirty # this failed.
    clerk.store(d)                    # so this would recurse forever




# * unit test runner

if __name__=="__main__":
    unittest.main()
